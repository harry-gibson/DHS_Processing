{
 "metadata": {
  "name": "",
  "signature": "sha256:4257d7a3785079bd033fa29853c5a24509f18e3f0618b83127e211298010d6ee"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Donal's Death Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This file contains code for producing custom output \"recode\" tables from DHS tables that have first been processed out into individual files for each survey and table (record type). \n",
      "\n",
      "Essentially it provides a means of \"joining\" tables given a specific master table (e.g. Child records or Woman records) and a list of tables / variables that should go into the output.\n",
      "\n",
      "The code for actually constructing the SQL that performs the joins is implemented in an external module that should be in the same directory as this notebook.\n",
      "\n",
      "This was developed by Harry Gibson for extracting information (potentially) related to Under 5 Mortality for Donal Bisanzio. However it should be applicable for creating any \"flat\" joined output tables from DHS data that has been parsed into separate tables from the CSPro format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import glob\n",
      "from collections import defaultdict\n",
      "import sqlite3\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from DHSTableManagement import *\n",
      "from UnicodeWriter import UnicodeWriter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#varsFile = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\Processing\\U5M_Universe_And_Everything_201510\\Info\\variables_chosen_edits.csv'\n",
      "#svyFile = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\Processing\\U5M_Universe_And_Everything_201510\\Info\\survey_db_list.csv'\n",
      "#tblPattern = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\DataExtraction\\20150626_FullSiteScrape\\ProcessedTables\\{0}.*.{1}.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "varsFile = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\Processing\\HouseholdElectricity_201511\\Info\\variables_for_hh_electric.csv'\n",
      "#svyFile = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\Processing\\U5M_Universe_And_Everything_201510\\Info\\survey_db_list.csv'\n",
      "tblPattern = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\DataExtraction\\20150626_FullSiteScrape\\ProcessedTables\\{0}.*.{1}.csv'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#outDir = r'\\\\129.67.26.176\\map_data\\hsg\\Donal'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outDir = r'\\\\129.67.26.176\\map_data\\DHS_Automation\\Processing\\HouseholdElectricity_201511\\Out'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load requirements from files provided by Donal"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allTables = [\"REC01\",\"REC11\",\"REC21\",\"REC22\",\"REC41\",\"REC42\",\"REC43\",\"REC44\",\"REC51\",\n",
      "             \"REC71\",\"REC75\",\"REC91\",\"REC94\",\"REC95\",\"RECH0\",\"RECH1\",\"RECH2\",\"RECH3\",\n",
      "             \"RECH4\",\"RECHM2\"]\n",
      "# \"RECH5\",\"RECH6\", missed as they contain nothing new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build a dictionary of the columns that have been requested for each table\n",
      "tableVars = defaultdict(list)\n",
      "with open(varsFile) as varfile:\n",
      "    reader = csv.DictReader(varfile,delimiter=',') # delim ; in original\n",
      "    for row in reader:\n",
      "        varname = row['Name']\n",
      "        recname = row['RecordName']\n",
      "        if 1:#recname in allTables:\n",
      "            tableVars[recname].append(varname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get files to read from survey_db_list\n",
      "with open(svyFile) as svyfile:\n",
      "    reader = csv.DictReader(svyfile)\n",
      "    svys = [row['DHS_id'] for row in reader]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'svyFile' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-9-9fbed958e996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get files to read from survey_db_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvyFile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msvyfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvyfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msvys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DHS_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'svyFile' is not defined"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svys= [os.path.basename(f).split('.')[0] \n",
      "       for f in glob.glob(tblPattern.format(\"*\", \"RECH0\"))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "['318',\n",
        " '267',\n",
        " '323',\n",
        " '490',\n",
        " '336',\n",
        " '259',\n",
        " '99',\n",
        " '311',\n",
        " '239',\n",
        " '426',\n",
        " '156',\n",
        " '297',\n",
        " '156',\n",
        " '253',\n",
        " '423',\n",
        " '399',\n",
        " '208',\n",
        " '392',\n",
        " '328',\n",
        " '364',\n",
        " '82',\n",
        " '156',\n",
        " '300',\n",
        " '76',\n",
        " '47',\n",
        " '396',\n",
        " '98',\n",
        " '111',\n",
        " '235',\n",
        " '363',\n",
        " '156',\n",
        " '94',\n",
        " '44',\n",
        " '156',\n",
        " '358',\n",
        " '38',\n",
        " '406',\n",
        " '92',\n",
        " '65',\n",
        " '447',\n",
        " '334',\n",
        " '156',\n",
        " '361',\n",
        " '156',\n",
        " '359',\n",
        " '51',\n",
        " '58',\n",
        " '356',\n",
        " '365',\n",
        " '32',\n",
        " '206',\n",
        " '41',\n",
        " '433',\n",
        " '156',\n",
        " '421',\n",
        " '222',\n",
        " '291',\n",
        " '349',\n",
        " '321',\n",
        " '53',\n",
        " '332',\n",
        " '156',\n",
        " '228',\n",
        " '204',\n",
        " '236',\n",
        " '156',\n",
        " '156',\n",
        " '89',\n",
        " '159',\n",
        " '115',\n",
        " '156',\n",
        " '156',\n",
        " '100',\n",
        " '333',\n",
        " '214',\n",
        " '135',\n",
        " '145',\n",
        " '114',\n",
        " '141',\n",
        " '34',\n",
        " '280',\n",
        " '174',\n",
        " '262',\n",
        " '46',\n",
        " '209',\n",
        " '216',\n",
        " '56',\n",
        " '227',\n",
        " '381',\n",
        " '326',\n",
        " '66',\n",
        " '81',\n",
        " '112',\n",
        " '294',\n",
        " '238',\n",
        " '340',\n",
        " '240',\n",
        " '157',\n",
        " '72',\n",
        " '302',\n",
        " '88',\n",
        " '87',\n",
        " '207',\n",
        " '83',\n",
        " '205',\n",
        " '257',\n",
        " '116',\n",
        " '282',\n",
        " '101',\n",
        " '434',\n",
        " '49',\n",
        " '439',\n",
        " '317',\n",
        " '354',\n",
        " '435',\n",
        " '156',\n",
        " '425',\n",
        " '255',\n",
        " '287',\n",
        " '156',\n",
        " '279',\n",
        " '362',\n",
        " '156',\n",
        " '388',\n",
        " '232',\n",
        " '298',\n",
        " '63',\n",
        " '271',\n",
        " '289',\n",
        " '443',\n",
        " '172',\n",
        " '357',\n",
        " '438',\n",
        " '397',\n",
        " '383',\n",
        " '331',\n",
        " '284',\n",
        " '338',\n",
        " '140',\n",
        " '61',\n",
        " '50',\n",
        " '45',\n",
        " '310',\n",
        " '277',\n",
        " '369',\n",
        " '77',\n",
        " '36',\n",
        " '329',\n",
        " '251',\n",
        " '48',\n",
        " '301',\n",
        " '158',\n",
        " '156',\n",
        " '407',\n",
        " '37',\n",
        " '154',\n",
        " '249',\n",
        " '64',\n",
        " '260',\n",
        " '403',\n",
        " '35',\n",
        " '324',\n",
        " '391',\n",
        " '233',\n",
        " '272',\n",
        " '110',\n",
        " '450',\n",
        " '156',\n",
        " '165',\n",
        " '295',\n",
        " '86',\n",
        " '456',\n",
        " '223',\n",
        " '156',\n",
        " '176',\n",
        " '70',\n",
        " '215',\n",
        " '95',\n",
        " '258',\n",
        " '248',\n",
        " '151',\n",
        " '152',\n",
        " '85',\n",
        " '346',\n",
        " '202',\n",
        " '327',\n",
        " '105',\n",
        " '106',\n",
        " '31',\n",
        " '96',\n",
        " '432',\n",
        " '368',\n",
        " '278',\n",
        " '337',\n",
        " '142',\n",
        " '230',\n",
        " '60',\n",
        " '402',\n",
        " '184',\n",
        " '309',\n",
        " '40',\n",
        " '203',\n",
        " '167',\n",
        " '273',\n",
        " '156',\n",
        " '293',\n",
        " '256',\n",
        " '266',\n",
        " '211',\n",
        " '62',\n",
        " '419',\n",
        " '169',\n",
        " '155',\n",
        " '156',\n",
        " '264',\n",
        " '156',\n",
        " '395',\n",
        " '147',\n",
        " '446',\n",
        " '69',\n",
        " '367',\n",
        " '90',\n",
        " '420',\n",
        " '268',\n",
        " '265',\n",
        " '33',\n",
        " '345',\n",
        " '436',\n",
        " '30',\n",
        " '210',\n",
        " '405',\n",
        " '59',\n",
        " '319',\n",
        " '296',\n",
        " '252',\n",
        " '384',\n",
        " '168',\n",
        " '113',\n",
        " '276',\n",
        " '109',\n",
        " '449',\n",
        " '42',\n",
        " '93',\n",
        " '330',\n",
        " '148',\n",
        " '457',\n",
        " '71',\n",
        " '156',\n",
        " '52',\n",
        " '156',\n",
        " '74',\n",
        " '156',\n",
        " '156',\n",
        " '156',\n",
        " '43']"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Process the surveys"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skipDB = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Load all CSV files for a survey into individual tables in the in-memory DB \n",
      "* Create indexes\n",
      "* Create an output table that is the result of joining them all\n",
      "* Write that to disk."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for svyID in svys:\n",
      "    print \"Survey \"+str(svyID)\n",
      "    # Use an in-memory sqlite db to load the tables and join them \n",
      "    db = sqlite3.connect(':memory:')\n",
      "    cursor = db.cursor()\n",
      "    srcTableInfos = {}\n",
      "    outname = os.path.join(outDir,\"HouseholdElectric.\"+str(svyID)+\".csv\")\n",
      "    for tblID, tblCols in tableVars.iteritems():\n",
      "        # Find the individual file required\n",
      "        tblFiles = glob.glob(tblPattern.format(svyID, tblID))\n",
      "        if len(tblFiles) != 1:\n",
      "            print (\"Survey \"+svyID+\" table \"+tblID+\" does not exist!\")\n",
      "            continue\n",
      "        print tblID +\"... \",\n",
      "        tblFile = tblFiles[0]\n",
      "        # Load the file to a DB table and also build a TableInfo for working with it\n",
      "        with open(tblFile) as tbl:\n",
      "            reader = csv.DictReader(tbl)\n",
      "            # ensure we get the ID variables which are CASEID or HIDX / BIDX etc\n",
      "            # Note that there are aalso HA0 and HC0 in RECH5/RECH6 but we don't actually\n",
      "            # need those tables (The only cols Donal requested cols from those tables \n",
      "            # are duplicated in the woman tableS)\n",
      "            # Note that the relative order of the id columns between the tables is important\n",
      "            # as it is used by the joiner code to figure out which columns match to which\n",
      "            # The fieldnames in the parsed files do give them in a consistent order,\n",
      "            # but it might be more relaxing to actually check that here (CASEID first then \n",
      "            # BIDX or whatever)\n",
      "            ids = [v for v in reader.fieldnames if v.find(\"ID\") != -1]\n",
      "            for i in ids:\n",
      "                if i not in tblCols:\n",
      "                    tblCols.insert(0, i)\n",
      "            # Create a tableinfo object which will handle building the sql necessary\n",
      "            # for interacting with this table in the database\n",
      "            srcTable = TableInfo(tblID, ids, tblCols)\n",
      "            srcTableInfos[tblID] = srcTable\n",
      "\n",
      "            if (skipDB):\n",
      "                # For debugging\n",
      "                continue\n",
      "\n",
      "            # Create the table in the database\n",
      "            createSql = srcTable.GetCreateTableSQL()\n",
      "            cursor.execute(createSql)\n",
      "            orderedCols = srcTable.AllColumns()\n",
      "            \n",
      "            # Populate the data into the DB from the CSV reader\n",
      "            insertSql = srcTable.GetInsertSQLTemplate()\n",
      "            # Use \"N/A\" for any columns that are not present in this survey\n",
      "            data = [([row.get(i, 'N/A') for i in orderedCols]) for row in reader ]\n",
      "            cursor.executemany(insertSql, data)\n",
      "            \n",
      "            # Create indexes in the DB on the relevant join columns\n",
      "            idxSql = srcTable.GetCreateIndexSQL()\n",
      "            cursor.executescript(idxSql)\n",
      "        db.commit()\n",
      "        \n",
      "    # Get a list of all table names with REC21 at the start. This will be the \n",
      "    # \"master table\" i.e. one output row for each row in REC21.\n",
      "    tblNames = [i for i in sorted(srcTableInfos) if i not in ['REC21']]\n",
      "    # Note that we also don't actually check here if the join is appropriate. \n",
      "    # For example from a Child master table we can join to its parents table and the household \n",
      "    # table. But we couldn't do the reverse as for each household there are many children.\n",
      "    # If we tried, we'd get repeated rows (probably) on the left join.\n",
      " \n",
      "    if (len(tblNames)) ==0:\n",
      "        print \"Nothing for survey \"+str(svyID)\n",
      "        continue\n",
      "    # Perform the join!\n",
      "    multi = MultiTableJoiner(\"outputTbl\", [srcTableInfos[n] for n in tblNames] )\n",
      "    cursor.execute(multi.GetCreateIntoSQL())\n",
      "    \n",
      "    # Write the results out to CSV\n",
      "    cursor.execute(\"select * from outputTbl\")\n",
      "    colNames = [description[0] for description in cursor.description]\n",
      "    with open(outname, \"wb\") as f:\n",
      "        writer = UnicodeWriter(f)\n",
      "        writer.writerow(colNames)\n",
      "        writer.writerows(cursor)\n",
      "    db.close()\n",
      "    print \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Survey 318\n",
        "RECH2... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " RECH0...  21\n",
        "21\n"
       ]
      },
      {
       "ename": "OperationalError",
       "evalue": "no such table: RECH0",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-14-07fea37d2d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Perform the join!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mmulti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiTableJoiner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"outputTbl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msrcTableInfos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtblNames\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetCreateIntoSQL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m# Write the results out to CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mOperationalError\u001b[0m: no such table: RECH0"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "glob.glob(tblPattern.format(svyID, tblID))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "['\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.PJIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.KEIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.HRIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.APIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.ARIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.ASIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.TRIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.TNIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.SKIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.HPIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.ORIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.JMIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.RJIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.BHIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.GOIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.WBIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.IAIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.MGIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.MHIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.UPIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.MPIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.MZIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.GJIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.NAIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.KAIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.MNIR42.RECH0.csv',\n",
        " '\\\\\\\\129.67.26.176\\\\map_data\\\\DHS_Automation\\\\DataExtraction\\\\20150626_FullSiteScrape\\\\ProcessedTables\\\\156.DLIR42.RECH0.csv']"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multi.GetCreateIntoSQL()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "21\n",
        "21\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "'CREATE TABLE outputTbl AS SELECT RECH0.HHID, RECH0.HV000, RECH0.HV001, RECH0.HV002, RECH0.HV005, RECH0.HV008, RECH0.HV009, RECH0.HV024, RECH0.HV025, RECH2.HHID, RECH2.HV201, RECH2.HV206, RECH2.HV207, RECH2.HV208, RECH2.HV209, RECH2.HV210, RECH2.HV211, RECH2.HV212, RECH2.HV221, RECH2.HV270, RECH2.HV271 from RECH0 LEFT JOIN RECH2 ON RECH0.HHID = RECH2.HHID'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Workings below this point - all redundant"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now the best thing to do would be then to join each of the other tables in turn and update, for example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inTable = srcTableInfos['REC43']\n",
      "cp = TableToTableFieldCopier(outTable, inTable, inTable.OutputColumns())\n",
      "\n",
      "update = cp.GetUpdateSQL_Join()\n",
      "cursor.execute(update)\n",
      "db.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "OperationalError",
       "evalue": "near \"INNER\": syntax error",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-90-7392b406013b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetUpdateSQL_Join\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# UPDATE {0} o INNER JOIN {1} i on o.{2} = i.{3} SET o.{4} = i.{5};\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mOperationalError\u001b[0m: near \"INNER\": syntax error"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But that doesn't work because it turns out SQLite doesn't support join in an update query. Nice to know."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inTable = srcTableInfos['REC43']\n",
      "cp = TableToTableFieldCopier(outTable, inTable, inTable.OutputColumns())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead we might try REPLACE INTO. But that doesn't work because it adds duplicate rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inTable = srcTableInfos['REC43']\n",
      "cp = TableToTableFieldCopier(outTable, inTable, inTable.OutputColumns())\n",
      "\n",
      "update = cp.GetUpdateSQL_Replace()\n",
      "cursor.execute(update)\n",
      "db.commit()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}